{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from resnet_utils import BasicBlock, Bottleneck, _resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def resnet18(pretrained=True, progress=True, **kwargs):\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet34(pretrained=True, progress=True, **kwargs):\n",
    "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet50(pretrained=True, progress=True, **kwargs):\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet101(pretrained=True, progress=True, **kwargs):\n",
    "    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet152(pretrained=True, progress=True, **kwargs):\n",
    "    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet_feature_model():\n",
    "    model = resnet18()\n",
    "    model = nn.Sequential(*list(model.classifier.children())[:-3])\n",
    "    return model\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model architecture for the VGG model\n",
    "class VGGish(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm([3, 242, 224])\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=3,out_channels=16, kernel_size=(7,7), stride=(1,1), padding=3),\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.Tanh(),\n",
    "                                   nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(5,5), stride=(1,1), padding=2),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), stride=(1,1), padding=1),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=1),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2))\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=1),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.Flatten(),\n",
    "                                        nn.Dropout(p=0.65),\n",
    "                                        nn.Linear(64*15*14, 64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(64, 7))\n",
    "\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.layer_norm(input_data)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        predictions = self.classifier(x)\n",
    "        #predictions = F.softmax(logits,dim=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(model_name, pretrained):\n",
    "\n",
    "    if (model_name == \"VGGish\"):\n",
    "        print(\"VGG !!!\")\n",
    "        model = VGGish()\n",
    "\n",
    "    elif (model_name == \"resnet18\"):\n",
    "\n",
    "        print(\"RESNET18 !!!\")\n",
    "        #model = resnet18()\n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=pretrained)\n",
    "        model.fc = nn.Linear(2048, 7)\n",
    "\n",
    "    elif (model_name == \"resnet50\"):\n",
    "\n",
    "        print(\"RESNET50 !!!\")\n",
    "        #model = resnet50()\n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=pretrained)\n",
    "        model.fc = nn.Linear(2048, 7)\n",
    "\n",
    "    elif (model_name == \"resnet101\"):\n",
    "\n",
    "        print(\"RESNET101 !!!\")\n",
    "        #model = resnet101()\n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=pretrained)\n",
    "        model.fc = nn.Linear(2048, 7)\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid model\")\n",
    "        print(\"Default VGG model used\")\n",
    "        model = VGGish()\n",
    "    print(model)\n",
    "\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
