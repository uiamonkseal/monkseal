{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "from torchvision import transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "from plotting import cfm, loss_acc_plot, plot_pr_roc_curve\n",
    "\n",
    "from models import select_model\n",
    "from dataloader import get_dataset\n",
    "from focalloss import Focal_Loss\n",
    "from config import Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Model():\n",
    "    def __init__(self, config, train_loader, val_loader, model):\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.model = model\n",
    "\n",
    "        self.net = select_model(model, config.pretrained)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.epochs = self.config.epochs\n",
    "        self.class_weights = class_weights=torch.tensor([1.061, 3.322,1.239,0.797,1.542,0.688,0.628],dtype=torch.float).to(self.device)\n",
    "        \n",
    "        # initialize metric\n",
    "        self.metric = torchmetrics.Accuracy()\n",
    "\n",
    "        \n",
    "        #initialize the loss function and opimizer\n",
    "        if self.config.lossfunction == 'FocalLoss':\n",
    "            self.criterion = Focal_Loss(self.config.fl_gamma)\n",
    "        else:\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        if self.config.optimizer == 'Adam':\n",
    "            self.optimizer = optim.Adam(self.net.parameters(),\n",
    "                                        lr=self.config.lr,\n",
    "                                        weight_decay=self.config.weight_decay)\n",
    "        else:\n",
    "            self.optimizer = optim.SGD(self.net.parameters(),\n",
    "                                       lr=self.config.lr,\n",
    "                                       momentum=self.config.momentum,\n",
    "                                       weight_decay=self.config.weight_decay)\n",
    "        \n",
    "        #initialize the scheduler, learning rate, batch size, train patience and the number of classes\n",
    "        self.scheduler = ReduceLROnPlateau(optimizer=self.optimizer , mode='min', patience=10, min_lr=1e-5,factor=0.5)\n",
    "        self.lr = self.config.lr\n",
    "        self.batch_size = self.config.batch_size\n",
    "        self.train_paitence = config.train_paitence\n",
    "        self.num_classes = len(self.config.class_mapping)\n",
    "\n",
    "    # functions for training the model\n",
    "    def train_single_epoch(self):\n",
    "        for file_data, target in self.train_loader:\n",
    "            file_data, target = file_data.to(self.device), target.to(self.device)\n",
    "\n",
    "            # calculate loss\n",
    "            prediction = self.net(file_data)\n",
    "            loss = self.criterion(prediction, target)\n",
    "            acc = self.metric(prediction, target)*100\n",
    "\n",
    "            # backpropagate error and update weights\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            del(file_data)\n",
    "            del(target)\n",
    "\n",
    "        print(f\"Loss: {loss.item()} | Acc: {acc}%\")\n",
    "\n",
    "        return loss, acc\n",
    "\n",
    "    # functions for training the model\n",
    "    def validation(self):\n",
    "        with torch.no_grad():\n",
    "            for file_data, target in self.val_loader:\n",
    "                file_data, target = file_data.to(self.device), target.to(self.device)\n",
    "\n",
    "                # calculate loss\n",
    "                prediction = self.net(file_data)\n",
    "                valid_loss = self.criterion(prediction, target)\n",
    "\n",
    "                valid_acc = self.metric(prediction, target)*100\n",
    "                del(file_data)\n",
    "                del(target)\n",
    "\n",
    "            print(f\"Val loss: {valid_loss.item()} | Val acc: {valid_acc}%\")\n",
    "\n",
    "        return valid_loss,valid_acc\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        global min_valid_loss\n",
    "        loss_history = []  # stores all loss values\n",
    "        valloss_history = []\n",
    "        acc_history = []  # stores all accuracy values\n",
    "        valacc_history = []\n",
    "        counter = []  # stores all the iterations\n",
    "        count_no_inprov = 0\n",
    "        min_valid_loss = np.inf\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            print(f\"Epoch {i + 1}\")\n",
    "            loss, acc = self.train_single_epoch()\n",
    "            valid_loss,valid_acc = self.validation()\n",
    "            self.scheduler.step(valid_loss)\n",
    "            counter.append(i)\n",
    "            loss_history.append(loss.item())\n",
    "            valloss_history.append(valid_loss.item())\n",
    "            acc_history.append(acc.detach().cpu())\n",
    "            valacc_history.append(valid_acc.detach().cpu())\n",
    "\n",
    "            if min_valid_loss > valid_loss:\n",
    "                min_valid_loss = valid_loss\n",
    "                count_no_inprov = 0\n",
    "                torch.save(self.net.state_dict(), self.config.model_dir + \"best_model.pth\")\n",
    "                print(\"Trained feed forward net saved at best_model.pth\")\n",
    "            else:\n",
    "                count_no_inprov+=1\n",
    "\n",
    "            if count_no_inprov > self.train_paitence:\n",
    "                print(\"[!] No improvement in a while, stopping training...\")\n",
    "                print(\"BEST VALIDATION LOSS: \", min_valid_loss)\n",
    "\n",
    "                break\n",
    "\n",
    "            print(\"-------------------------------------------------\")\n",
    "        torch.save(self.net.state_dict(), self.config.model_dir + \"last_model.pth\")\n",
    "        print(\"Trained feed forward net saved at last_model.pth\")\n",
    "        print(\"Finished training\")\n",
    "        loss_acc_plot(counter, loss_history, valloss_history, acc_history, valacc_history, self.config.results_dir)\n",
    "\n",
    "\n",
    "    def test(self, dataset):\n",
    "        state_dict = torch.load(self.config.model_dir + \"best_model.pth\")\n",
    "        self.net.load_state_dict(state_dict)\n",
    "        self.net.eval()\n",
    "        correct = []  # stores all the accurate predictions\n",
    "        calls = []  # stores all the accurate predicitons for each call\n",
    "        for _ in range(len(self.config.class_mapping)):\n",
    "            calls.append([])\n",
    "        y_true = []  # stores all the expected calls\n",
    "        y_pred = []  # stores all the predicted calls\n",
    "        target_list = []  # stores a list with all the target values\n",
    "        prediction_list = []  # stores a list with all the predictions\n",
    "        with torch.no_grad():\n",
    "            for input, target in dataset:# [batch size, num_channels, fr, time]\n",
    "                input.unsqueeze_(0)\n",
    "                Y = np.zeros(len(self.config.class_mapping))\n",
    "                input = input.to(self.device)\n",
    "\n",
    "                predictions = self.net(input)\n",
    "\n",
    "                predictions = F.softmax(predictions,dim=1).cpu().numpy()\n",
    "                predicted_index = predictions[0].argmax(0)\n",
    "\n",
    "                predicted = predicted_index\n",
    "                Y[target] = 1\n",
    "\n",
    "                # storing the values for confusion matrix and precision-recall curve\n",
    "                target_list.append(Y)\n",
    "                prediction_list.append(predictions.squeeze().tolist())\n",
    "                y_pred.append(predicted)\n",
    "                y_true.append(target)\n",
    "\n",
    "                # checking all the total correct preditions\n",
    "                if predicted == target:\n",
    "                    correct.append(1)\n",
    "                else:\n",
    "                    correct.append(0)\n",
    "\n",
    "                # checking all the correct preditions for each call\n",
    "                for index in range(len(self.config.class_mapping)):  # zip(range(len(class_mapping)), class_mapping):\n",
    "                    if target == index:\n",
    "                        if predicted == target:\n",
    "                            calls[index].append(1)\n",
    "                        else:\n",
    "                            calls[index].append(0)\n",
    "\n",
    "        # Calculation total accuracy\n",
    "        accuracy = sum(correct) / len(correct)\n",
    "        print(f\"Accuracy:  {accuracy :.3f}\")\n",
    "        print(str(sum(correct)) + ' of ' + str(len(correct)))\n",
    "\n",
    "        # Calculation accuracy for each call\n",
    "        call_accuracies = np.zeros(len(self.config.class_mapping))\n",
    "\n",
    "        for index, class_ in zip(range(len(self.config.class_mapping)), self.config.class_mapping):\n",
    "            call_accuracies[index] = sum(calls[index]) / len(calls[index]) if len(calls[index]) != 0 else 0\n",
    "\n",
    "            print(f\"Accuracy for {class_}:  {call_accuracies[index] :.3f}\")\n",
    "            print(str(sum(calls[index])) + ' of ' + str(len(calls[index])))\n",
    "\n",
    "        cfm(y_true,y_pred,self.config.results_dir,self.config.class_mapping)\n",
    "        plot_pr_roc_curve(target_list,prediction_list,self.config.results_dir,self.config.class_mapping)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
